{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ycnnn/STAT542/blob/main/ver1Project1STAT542.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcv61i_4C_4r"
      },
      "source": [
        "Import basic packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X0xT9LUcVCWn"
      },
      "outputs": [],
      "source": [
        "#import basic libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtFs4Pvbdzfx"
      },
      "source": [
        "Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "k_pM6_pJVcEx"
      },
      "outputs": [],
      "source": [
        "def preprocess(train_raw, test_raw):\n",
        "\n",
        "    train_y_raw = train_raw['Sale_Price']\n",
        "    train_raw = train_raw.drop(['PID','Sale_Price'], axis = 1)\n",
        "    test_raw = test_raw.drop(['PID'], axis = 1)\n",
        "    \n",
        "    #first, fill all NaN values with 0\n",
        "    train_raw = train_raw.fillna(0)\n",
        "    test_raw = test_raw.fillna(0)\n",
        "\n",
        "\n",
        "    #next, do dummy coding\n",
        "    #first, pick out cat variables and numerical variables\n",
        "\n",
        "    cat_var = []\n",
        "    num_var = []\n",
        "\n",
        "    for var in train_raw.keys().tolist():\n",
        "        if train_raw[var].dtype == 'O':\n",
        "            cat_var.append(var)\n",
        "        else:\n",
        "            num_var.append(var)\n",
        "\n",
        "\n",
        "    #dummy coding train set\n",
        "    #colinearity checked\n",
        "    ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "    enc = ohe.fit_transform(train_raw[cat_var])\n",
        "    #Converting back to a dataframe \n",
        "    train_dummy = pd.DataFrame(enc, columns=ohe.get_feature_names_out())\n",
        "    test_dummy = pd.DataFrame(ohe.transform(test_raw[cat_var]), columns=ohe.get_feature_names_out())\n",
        "\n",
        "    train_encoded = pd.concat([train_dummy,train_raw[num_var]], axis = 1)\n",
        "    test_encoded = pd.concat([test_dummy,test_raw[num_var]], axis = 1)\n",
        "\n",
        "    train_np = train_encoded.to_numpy()\n",
        "    test_np = test_encoded.to_numpy()\n",
        "\n",
        "    train_y_np = train_y_raw.to_numpy()\n",
        "\n",
        "    return train_np, train_y_np, test_np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXUJJo__BwIx"
      },
      "source": [
        "Model: boosting tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "QseA8DHjcu0Z"
      },
      "outputs": [],
      "source": [
        "def boost_tree_pred(train, train_y, test, tree_n = 10000):\n",
        "    #define the model\n",
        "\n",
        "    xgb_r = xgb.XGBRegressor(objective ='reg:squarederror', n_estimators = tree_n, \n",
        "                             max_depth=5, learning_rate=0.015, subsample=0.5,\n",
        "                             colsample_bytree = 0.8, booster='dart',\n",
        "                             reg_lambda=0.5)\n",
        "   \n",
        "\n",
        "    # Fitting the model\n",
        "    xgb_r.fit(train, train_y)  \n",
        "    # Predict the model\n",
        "    pred = xgb_r.predict(test)\n",
        "    \n",
        "    return pred"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rmsle_calculate(predictions, dmat):\n",
        "    labels = dmat.get_label()\n",
        "    diffs = np.log(predictions + 1) - np.log(labels + 1)\n",
        "    squared_diffs = np.square(diffs)\n",
        "    avg = np.mean(squared_diffs)\n",
        "    return ('RMSLE', np.sqrt(avg))\n",
        "\n",
        "    ###############################################################################################\n",
        "\n",
        "def rmsle(train, train_y, test,test_y,tree_n=5000):\n",
        "    '''Train using native implementation of Squared Log Error.'''\n",
        "\n",
        "    dtrain = xgb.DMatrix(train, train_y)\n",
        "    dtest = xgb.DMatrix(test, test_y)\n",
        "\n",
        "    squared_log_error = {\n",
        "        'objective': 'reg:squarederror',\n",
        "        'tree_method': 'hist',\n",
        "        'seed': 0,\n",
        "        'learning_rates': 0.05,\n",
        "        'max_depth':8,\n",
        "        'sub_sample':0.5,\n",
        "        'booster':'dart'\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "    bst = xgb.train(squared_log_error,\n",
        "              dtrain=dtrain,\n",
        "              num_boost_round=tree_n)\n",
        "\n",
        "\n",
        "\n",
        "    pred=bst.predict(dtest)\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "qEBAGDRNuztZ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG3AlPieMWfa"
      },
      "source": [
        "Import data. Data is read then pre-processed, and conveted into Numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ig9gDUzCVKfv"
      },
      "outputs": [],
      "source": [
        "folds = 10\n",
        "rmse = np.zeros(folds)\n",
        "\n",
        "#load data\n",
        "for ids in range(4,5):\n",
        "\n",
        "    train_raw = pd.read_csv(f\"train_{ids}.csv\")\n",
        "    test_raw = pd.read_csv(f\"test_feature_{ids}.csv\")\n",
        "    test_y_raw = pd.read_csv(f\"test_y_{ids}.csv\")\n",
        "\n",
        "    train, train_y, test = preprocess(train_raw, test_raw)\n",
        "    test_y = test_y_raw.to_numpy().ravel()\n",
        "\n",
        "    pred = boost_tree_pred(train, train_y, test)\n",
        "    #pred = rmsle(train, train_y, test, test_y)\n",
        "    \n",
        "    rmse[ids] = np.sqrt(np.mean((np.log(pred) - np.log(test_y))**2))\n",
        "    print(f'id:{ids}',rmse[ids])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xTL0wJbaEQM"
      },
      "source": [
        "def boost_tree_pred(train, train_y, test, tree_n = 5000):\n",
        "    #define the model\n",
        "\n",
        "    xgb_r = xgb.XGBRegressor(objective ='reg:squarederror', n_estimators = tree_n, \n",
        "                             max_depth=5, learning_rate=0.015, subsample=0.6,\n",
        "                             colsample_bytree = 1)\n",
        "\n",
        "   \n",
        "\n",
        "    # Fitting the model\n",
        "    xgb_r.fit(train, train_y)  \n",
        "    # Predict the model\n",
        "    pred = xgb_r.predict(test)\n",
        "    \n",
        "    return pred\n",
        "\n",
        "    id:3 0.12395951345672147\n",
        "id:4 0.12816665854664458"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HBJA2khuG0r3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyPHRww8Iq007OdWFgxMiZZQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}